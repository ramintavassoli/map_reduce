{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Given a big data set of wikipedia pages, the goal is to find the top occuring words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To achieve this, words associated with metadata such as HTML tags are discounted.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mrjob.job import MRJob\n",
    "from mrjob.step import MRStep\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import heapq as hq\n",
    "import mwparserfromhell\n",
    "\n",
    "WORD_RE = re.compile(r\"\\w+\")\n",
    "START_RE = re.compile('.*<page>.*')\n",
    "END_RE= re.compile('.*</page>.*')\n",
    "\n",
    "class stripper(MRJob):\n",
    "\n",
    "        def mapper_init(self):\n",
    "                self.page = ''\n",
    "                self.key = 0\n",
    "\n",
    "        def mapper(self,_,line):\n",
    "\n",
    "                if END_RE.match(line):\n",
    "                        self.page = self.page + line.strip()\n",
    "                        yield (self.key, self.page)\n",
    "                        self.key += 1\n",
    "\n",
    "                elif START_RE.match(line):\n",
    "                        self.page = ''\n",
    "                        self.page = self.page + line.strip()\n",
    "                else:\n",
    "                        self.page = self.page + line.strip()\n",
    "\n",
    "        def reducer(self, key, page):\n",
    "                yield (key, page)\n",
    "\n",
    "class stripper_2(MRJob):\n",
    "\n",
    "        def mapper(self, _, pages):\n",
    "                for page in pages:\n",
    "                        soup = bs(page, 'lxml')\n",
    "                        for item in soup.find_all('text'):\n",
    "                                parsed = mwparserfromhell.parse(item.text)\n",
    "                                for word in WORD_RE.findall(parsed.strip_code()):\n",
    "                                        yield (word.lower(), 1)\n",
    "\n",
    "        def reducer(self, word, counts):\n",
    "                yield (word, sum(counts))\n",
    "\n",
    "\n",
    "class stripper_3(MRJob):\n",
    "\n",
    "        def mapper_init(self):\n",
    "                self.lst_tuples = []\n",
    "\n",
    "        def mapper(self, word, counts):\n",
    "                hq.heappush(self.lst_tuples, (counts, word))\n",
    "\n",
    "        def mapper_final(self):\n",
    "                for item in hq.nlargest(100, self.lst_tuples):\n",
    "                        yield (item[1], item[0])\n",
    "\n",
    "        def reducer_init(self):\n",
    "                self.lst_tuples_ = []\n",
    "\n",
    "        def reducer(self, word, counts):\n",
    "                hq.heappush(self.lst_tuples_, (sum(counts), word))\n",
    "\n",
    "        def reducer_final(self):\n",
    "                for item in hq.nlargest(100, self.lst_tuples_):\n",
    "                        yield (item[1], item[0])\n",
    "\n",
    "\n",
    "class SteppedJob(MRJob):\n",
    "        def steps(self):\n",
    "                return stripper().steps() + stripper_2().steps() + stripper_3().steps()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "        SteppedJob.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I ran the code above in CLI and stored the output in output.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('output.txt', 'rb') as file:\n",
    "    words = []\n",
    "    counts = []\n",
    "    for line in file:\n",
    "        line = line.strip('\\n')\n",
    "        splited = line.split('\\t')\n",
    "        words.append(splited[0])\n",
    "        counts.append(int(splited[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'of', 'in', 'and', 'a', 'to', 'is', 'was', 'it', 'for', 'on', '0', 'that', 's', 'as', 'align', 'by', 'are', '1', 'from', '2', 'he', 'with', 'this', 'be', 'i', 'or', 'category', 'at', 'an', 'center', 'not', 'style', '3', 'other', 'they', 'his', 'have', 'utc', 'people', 'has', 'talk', 'also', 'american', 'bgcolor', 'one', '4', 'right', 'which', 'can', 'but', 'were', 'new', 'first', '5', 'there', 'you', 'b', 'references', 'rowspan', 'left', '6', 'd', 'about', 'redirect', 't', 'if', 'all', 'may', 'font', 'when', 'their', 'who', 'thumb', 'used', 'had', 'after', '10', 'more', 'many', 'color', 'some', '2009', 'she', 'made', 'united', 'user', '7', 'time', 'city', 'background', 'two', '2008', 'no', 'world', 'its', 'most', 'called', '8', 'english']\n"
     ]
    }
   ],
   "source": [
    "trimmed_words = []\n",
    "for word in words:\n",
    "    trimmed_words.append(word.split('\"')[1])\n",
    "print(trimmed_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 1430692), ('of', 747428), ('in', 586232), ('and', 547669), ('a', 517123), ('to', 417330), ('is', 391092), ('was', 209485), ('it', 206636), ('for', 185137), ('on', 163090), ('0', 157286), ('that', 154468), ('s', 152065), ('as', 148802), ('align', 141510), ('by', 132262), ('are', 129040), ('1', 126803), ('from', 126512), ('2', 125455), ('he', 122979), ('with', 121300), ('this', 109145), ('be', 101359), ('i', 101152), ('or', 95304), ('category', 95291), ('at', 94522), ('an', 94144), ('center', 92033), ('not', 86868), ('style', 80096), ('3', 77762), ('other', 76109), ('they', 75353), ('his', 72995), ('have', 66943), ('utc', 65867), ('people', 65017), ('has', 63434), ('talk', 61312), ('also', 60630), ('american', 59581), ('bgcolor', 59079), ('one', 58981), ('4', 57901), ('right', 57859), ('which', 54563), ('can', 54264), ('but', 53599), ('were', 52494), ('new', 51013), ('first', 50759), ('5', 50719), ('there', 50628), ('you', 45617), ('b', 45561), ('references', 44545), ('rowspan', 43590), ('left', 43425), ('6', 43356), ('d', 41832), ('about', 41708), ('redirect', 41102), ('t', 40327), ('if', 39743), ('all', 39521), ('may', 39457), ('font', 38554), ('when', 38310), ('their', 38244), ('who', 38193), ('thumb', 37075), ('used', 36542), ('had', 35960), ('after', 35905), ('10', 35851), ('more', 35631), ('many', 35549), ('color', 35482), ('some', 35277), ('2009', 35191), ('she', 34985), ('made', 34736), ('united', 34638), ('user', 34568), ('7', 34458), ('time', 34258), ('city', 34255), ('background', 33736), ('two', 31999), ('2008', 31983), ('no', 31620), ('world', 31535), ('its', 31414), ('most', 31343), ('called', 31175), ('8', 30583), ('english', 30287)]\n"
     ]
    }
   ],
   "source": [
    "zipped = zip(trimmed_words, counts)\n",
    "print(zipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2927387),\n",
       " ('of', 1748781),\n",
       " ('in', 1199343),\n",
       " ('and', 1147630),\n",
       " ('a', 1065119),\n",
       " ('to', 824917),\n",
       " ('is', 751640),\n",
       " ('ref', 678208),\n",
       " ('s', 532012),\n",
       " ('1', 438216),\n",
       " ('0', 401109),\n",
       " ('it', 398436),\n",
       " ('was', 394008),\n",
       " ('for', 385220),\n",
       " ('text', 381110),\n",
       " ('2', 367002),\n",
       " ('on', 344698),\n",
       " ('name', 324024),\n",
       " ('br', 301598),\n",
       " ('that', 295848),\n",
       " ('as', 290810),\n",
       " ('font', 288553),\n",
       " ('by', 274275),\n",
       " ('align', 270913),\n",
       " ('user', 270367),\n",
       " ('from', 263904),\n",
       " ('are', 247744),\n",
       " ('with', 243735),\n",
       " ('he', 235118),\n",
       " ('this', 221476),\n",
       " ('i', 221453),\n",
       " ('com', 221437),\n",
       " ('3', 220144),\n",
       " ('talk', 209190),\n",
       " ('title', 208315),\n",
       " ('at', 204630),\n",
       " ('center', 201554),\n",
       " ('be', 200936),\n",
       " ('or', 194045),\n",
       " ('small', 188935),\n",
       " ('an', 185689),\n",
       " ('not', 171186),\n",
       " ('space', 170689),\n",
       " ('new', 169601),\n",
       " ('people', 165587),\n",
       " ('football', 165265),\n",
       " ('4', 164687),\n",
       " ('b', 162805),\n",
       " ('xml', 156476),\n",
       " ('preserve', 155883),\n",
       " ('united', 153944),\n",
       " ('first', 153701),\n",
       " ('cite', 149836),\n",
       " ('date', 148415),\n",
       " ('5', 147804),\n",
       " ('other', 147728),\n",
       " ('they', 143129),\n",
       " ('url', 142905),\n",
       " ('his', 141481),\n",
       " ('if', 140651),\n",
       " ('span', 139026),\n",
       " ('american', 132483),\n",
       " ('states', 130042),\n",
       " ('one', 129840),\n",
       " ('have', 128330),\n",
       " ('stub', 121908),\n",
       " ('has', 121482),\n",
       " ('c', 121424),\n",
       " ('right', 120671),\n",
       " ('6', 118513),\n",
       " ('accessdate', 117012),\n",
       " ('10', 116038),\n",
       " ('also', 115736),\n",
       " ('2009', 115010),\n",
       " ('player', 112085),\n",
       " ('2008', 111997),\n",
       " ('web', 111813),\n",
       " ('can', 109660),\n",
       " ('d', 109143),\n",
       " ('publisher', 107930),\n",
       " ('n', 106116),\n",
       " ('2010', 105522),\n",
       " ('which', 104943),\n",
       " ('but', 103043),\n",
       " ('sup', 102602),\n",
       " ('county', 101774),\n",
       " ('m', 99817),\n",
       " ('were', 99364),\n",
       " ('league', 99305),\n",
       " ('file', 97936),\n",
       " ('city', 97901),\n",
       " ('2011', 97580),\n",
       " ('world', 96837),\n",
       " ('there', 96688),\n",
       " ('year', 95556),\n",
       " ('7', 95374),\n",
       " ('france', 95254),\n",
       " ('may', 94068),\n",
       " ('you', 93818),\n",
       " ('national', 92525),\n",
       " ('left', 92482),\n",
       " ('t', 92112),\n",
       " ('2007', 91408),\n",
       " ('12', 89362),\n",
       " ('8', 88734),\n",
       " ('about', 85960),\n",
       " ('no', 85073),\n",
       " ('all', 84456),\n",
       " ('11', 84262),\n",
       " ('html', 83581),\n",
       " ('background', 83459),\n",
       " ('org', 82826),\n",
       " ('york', 81496),\n",
       " ('f', 81423),\n",
       " ('time', 81274),\n",
       " ('2012', 81272),\n",
       " ('english', 80440)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_zipped = []\n",
    "for n in zipped:\n",
    "    if n[0] in  ['de', 'bgcolor', 'page', 'category', 'style', 'references', 'infobox', 'image', 'redirect', 'width', 'colspan', 'rowspan', 'thumb', 'www', 'http', 'jpg', 'color', 'utc']:\n",
    "        continue\n",
    "    else:\n",
    "        new_zipped.append(n)\n",
    "        \n",
    "new_zipped"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
